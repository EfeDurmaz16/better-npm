import test from "node:test";
import assert from "node:assert/strict";
import fs from "node:fs/promises";
import path from "node:path";
import { execFile } from "node:child_process";
import { promisify } from "node:util";
import { makeTempDir, rmrf, writeFile, writeJson } from "./helpers.js";

const execFileAsync = promisify(execFile);
const betterBin = path.resolve(process.cwd(), "bin", "better.js");

/**
 * Helper to run benchmark and parse JSON output.
 */
async function runBenchmark(dir, args = [], env = {}) {
  const { stdout } = await execFileAsync(
    process.execPath,
    [betterBin, "benchmark", ...args],
    {
      cwd: dir,
      env: {
        ...process.env,
        BETTER_LOG_LEVEL: "silent",
        ...env
      },
      timeout: 120_000
    }
  );
  return JSON.parse(stdout);
}

/**
 * Create a fake PM binary that mimics install behavior.
 * Each fake binary creates node_modules/fake/package.json and exits 0.
 */
async function createFakePmBinary(binDir, name) {
  const binPath = path.join(binDir, name);
  await writeFile(
    binPath,
    [
      "#!/bin/sh",
      "mkdir -p node_modules/fake",
      `cat > node_modules/fake/package.json <<'JSON'`,
      `{"name":"fake","version":"1.0.0"}`,
      "JSON",
      "exit 0",
      ""
    ].join("\n")
  );
  await fs.chmod(binPath, 0o755);
  return binPath;
}

/**
 * Create a test project with package.json, package-lock.json, and fake PM binaries.
 */
async function createTestProject(dir, opts = {}) {
  const { pm = "npm" } = opts;

  await writeJson(path.join(dir, "package.json"), {
    name: "comparative-bench-test",
    version: "1.0.0"
  });

  await writeJson(path.join(dir, "package-lock.json"), {
    name: "comparative-bench-test",
    lockfileVersion: 3,
    packages: {
      "": { name: "comparative-bench-test", version: "1.0.0" }
    }
  });

  // pnpm needs a pnpm-lock.yaml
  if (pm === "pnpm") {
    await writeFile(
      path.join(dir, "pnpm-lock.yaml"),
      [
        "lockfileVersion: '6.0'",
        "settings:",
        "  autoInstallPeers: true",
        "packages: {}",
        ""
      ].join("\n")
    );
  }

  // yarn needs a yarn.lock
  if (pm === "yarn") {
    await writeFile(
      path.join(dir, "yarn.lock"),
      [
        "# THIS IS AN AUTOGENERATED FILE.",
        "# yarn lockfile v1",
        "",
        ""
      ].join("\n")
    );
  }

  // Create fake binaries for all PMs
  const fakeBin = path.join(dir, "fake-bin");
  await fs.mkdir(fakeBin, { recursive: true });
  await createFakePmBinary(fakeBin, "npm");
  await createFakePmBinary(fakeBin, "pnpm");
  await createFakePmBinary(fakeBin, "yarn");
  await createFakePmBinary(fakeBin, "bun");

  return { fakeBin };
}

// ── npm baseline ───────────────────────────────────────────────────────

test("comparative: npm baseline produces valid schema", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-npm-");
  try {
    const { fakeBin } = await createTestProject(dir);

    const report = await runBenchmark(
      dir,
      ["--project-root", ".", "--pm", "npm", "--engine", "pm",
       "--cold-rounds", "1", "--warm-rounds", "1", "--json"],
      { PATH: `${fakeBin}:${process.env.PATH ?? ""}` }
    );

    assert.equal(report.ok, true);
    assert.equal(report.kind, "better.benchmark");
    assert.equal(report.schemaVersion, 2);
    assert.equal(report.pm.selected, "npm");
    assert.equal(report.engine, "pm");
    assert.ok(report.variants.raw, "should have raw variant");
    assert.ok(report.variants.betterMinimal, "should have betterMinimal variant");
    assert.ok(report.comparison, "should have comparison");
  } finally {
    await rmrf(dir);
  }
});

// ── pnpm comparison ────────────────────────────────────────────────────

test("comparative: pnpm produces valid benchmark report", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-pnpm-");
  try {
    const { fakeBin } = await createTestProject(dir, { pm: "pnpm" });

    const report = await runBenchmark(
      dir,
      ["--project-root", ".", "--pm", "pnpm", "--engine", "pm",
       "--cold-rounds", "1", "--warm-rounds", "1", "--json"],
      { PATH: `${fakeBin}:${process.env.PATH ?? ""}` }
    );

    assert.equal(report.ok, true);
    assert.equal(report.pm.selected, "pnpm");
    assert.equal(report.engine, "pm");
    assert.ok(report.variants.raw, "should have raw variant");
    assert.ok(report.variants.raw.cold.length > 0, "should have cold samples");
    assert.ok(report.variants.raw.warm.length > 0, "should have warm samples");
  } finally {
    await rmrf(dir);
  }
});

// ── yarn comparison ────────────────────────────────────────────────────

test("comparative: yarn produces valid benchmark report", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-yarn-");
  try {
    const { fakeBin } = await createTestProject(dir, { pm: "yarn" });

    const report = await runBenchmark(
      dir,
      ["--project-root", ".", "--pm", "yarn", "--engine", "pm",
       "--cold-rounds", "1", "--warm-rounds", "1", "--json"],
      { PATH: `${fakeBin}:${process.env.PATH ?? ""}` }
    );

    assert.equal(report.ok, true);
    assert.equal(report.pm.selected, "yarn");
    assert.equal(report.engine, "pm");
    assert.ok(report.variants.raw, "should have raw variant");
    assert.ok(report.variants.raw.cold.length > 0, "should have cold samples");
    assert.ok(report.variants.raw.warm.length > 0, "should have warm samples");
  } finally {
    await rmrf(dir);
  }
});

// ── bun engine comparison ──────────────────────────────────────────────

test("comparative: bun engine produces valid benchmark report", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-bun-");
  try {
    const { fakeBin } = await createTestProject(dir);

    const report = await runBenchmark(
      dir,
      ["--project-root", ".", "--pm", "npm", "--engine", "bun",
       "--cold-rounds", "1", "--warm-rounds", "1", "--json"],
      { PATH: `${fakeBin}:${process.env.PATH ?? ""}` }
    );

    assert.equal(report.ok, true);
    assert.equal(report.engine, "bun");
    assert.ok(report.variants.raw, "should have raw variant");
    assert.ok(report.variants.betterMinimal, "should have betterMinimal variant");
  } finally {
    await rmrf(dir);
  }
});

// ── comparison delta structure ─────────────────────────────────────────

test("comparative: comparison contains deltaMs and deltaPercent", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-delta-");
  try {
    const { fakeBin } = await createTestProject(dir);

    const report = await runBenchmark(
      dir,
      ["--project-root", ".", "--pm", "npm", "--engine", "pm",
       "--cold-rounds", "1", "--warm-rounds", "2", "--json"],
      { PATH: `${fakeBin}:${process.env.PATH ?? ""}` }
    );

    assert.ok(report.comparison, "comparison should exist");
    assert.ok("deltaMs" in report.comparison, "should have deltaMs");
    assert.ok("deltaPercent" in report.comparison, "should have deltaPercent");
    assert.ok("rawWarmMedianMs" in report.comparison, "should have rawWarmMedianMs");
    assert.ok("betterWarmMedianMs" in report.comparison, "should have betterWarmMedianMs");
    assert.ok("wrapperTaxMs" in report.comparison, "should have wrapperTaxMs");

    // Delta should be a number (positive or negative) when both medians exist
    if (report.comparison.rawWarmMedianMs != null && report.comparison.betterWarmMedianMs != null) {
      assert.equal(typeof report.comparison.deltaMs, "number", "deltaMs should be number");
      assert.equal(typeof report.comparison.deltaPercent, "number", "deltaPercent should be number");
    }
  } finally {
    await rmrf(dir);
  }
});

// ── byScenario across PMs ─────────────────────────────────────────────

test("comparative: byScenario entries for npm all scenario", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-byscenario-");
  try {
    const { fakeBin } = await createTestProject(dir);

    const report = await runBenchmark(
      dir,
      ["--project-root", ".", "--pm", "npm", "--engine", "pm",
       "--scenario", "all", "--cold-rounds", "1", "--warm-rounds", "1", "--json"],
      { PATH: `${fakeBin}:${process.env.PATH ?? ""}` }
    );

    const byScenario = report.comparison.byScenario;
    assert.ok(Array.isArray(byScenario), "byScenario should be an array");
    assert.equal(byScenario.length, 2, "all scenario should produce 2 entries");

    const scenarios = byScenario.map(s => s.scenario);
    assert.ok(scenarios.includes("cold_miss"), "should include cold_miss");
    assert.ok(scenarios.includes("warm_hit"), "should include warm_hit");

    for (const entry of byScenario) {
      assert.ok("rawMedianMs" in entry, `${entry.scenario} should have rawMedianMs`);
      assert.ok("betterMedianMs" in entry, `${entry.scenario} should have betterMedianMs`);
      assert.ok("deltaMs" in entry, `${entry.scenario} should have deltaMs`);
      assert.ok("deltaPercent" in entry, `${entry.scenario} should have deltaPercent`);
    }
  } finally {
    await rmrf(dir);
  }
});

// ── cross-PM stats shape consistency ───────────────────────────────────

test("comparative: stats shape is consistent across npm and pnpm", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dirNpm = await makeTempDir("comp-bench-stats-npm-");
  const dirPnpm = await makeTempDir("comp-bench-stats-pnpm-");
  try {
    const { fakeBin: fakeBinNpm } = await createTestProject(dirNpm);
    const { fakeBin: fakeBinPnpm } = await createTestProject(dirPnpm, { pm: "pnpm" });

    const [npmReport, pnpmReport] = await Promise.all([
      runBenchmark(
        dirNpm,
        ["--project-root", ".", "--pm", "npm", "--engine", "pm",
         "--cold-rounds", "0", "--warm-rounds", "2", "--json"],
        { PATH: `${fakeBinNpm}:${process.env.PATH ?? ""}` }
      ),
      runBenchmark(
        dirPnpm,
        ["--project-root", ".", "--pm", "pnpm", "--engine", "pm",
         "--cold-rounds", "0", "--warm-rounds", "2", "--json"],
        { PATH: `${fakeBinPnpm}:${process.env.PATH ?? ""}` }
      )
    ]);

    // Both should have the same stats shape
    const npmStats = npmReport.variants.raw.stats.warm;
    const pnpmStats = pnpmReport.variants.raw.stats.warm;

    const expectedKeys = ["count", "min", "max", "mean", "median", "p95", "stddev", "p95Spread"];
    for (const key of expectedKeys) {
      assert.ok(key in npmStats, `npm stats should have ${key}`);
      assert.ok(key in pnpmStats, `pnpm stats should have ${key}`);
    }

    assert.equal(npmStats.count, 2, "npm warm count should be 2");
    assert.equal(pnpmStats.count, 2, "pnpm warm count should be 2");
  } finally {
    await Promise.all([rmrf(dirNpm), rmrf(dirPnpm)]);
  }
});

// ── include-full variant ───────────────────────────────────────────────

test("comparative: --include-full adds betterFull variant", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-full-");
  try {
    const { fakeBin } = await createTestProject(dir);

    const report = await runBenchmark(
      dir,
      ["--project-root", ".", "--pm", "npm", "--engine", "pm",
       "--cold-rounds", "0", "--warm-rounds", "1", "--include-full", "--json"],
      { PATH: `${fakeBin}:${process.env.PATH ?? ""}` }
    );

    assert.ok(report.variants.raw, "should have raw variant");
    assert.ok(report.variants.betterMinimal, "should have betterMinimal variant");
    assert.ok(report.variants.betterFull, "should have betterFull variant");
    assert.ok(report.variants.betterFull.stats, "betterFull should have stats");
    assert.ok(report.variants.betterFull.stats.warm, "betterFull should have warm stats");
  } finally {
    await rmrf(dir);
  }
});

// ── frozen flag forwarding ─────────────────────────────────────────────

test("comparative: --frozen flag is captured in config", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-frozen-");
  try {
    const { fakeBin } = await createTestProject(dir);

    const report = await runBenchmark(
      dir,
      ["--project-root", ".", "--pm", "npm", "--engine", "pm",
       "--cold-rounds", "0", "--warm-rounds", "1", "--frozen", "--json"],
      { PATH: `${fakeBin}:${process.env.PATH ?? ""}` }
    );

    assert.equal(report.config.frozen, true, "config.frozen should be true");
  } finally {
    await rmrf(dir);
  }
});

// ── PM detection field ─────────────────────────────────────────────────

test("comparative: pm field shows selected vs detected", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-pmfield-");
  try {
    const { fakeBin } = await createTestProject(dir);

    const report = await runBenchmark(
      dir,
      ["--project-root", ".", "--pm", "npm", "--engine", "pm",
       "--cold-rounds", "0", "--warm-rounds", "1", "--json"],
      { PATH: `${fakeBin}:${process.env.PATH ?? ""}` }
    );

    assert.ok(report.pm, "pm field should exist");
    assert.equal(report.pm.selected, "npm", "pm.selected should be npm");
    assert.ok(typeof report.pm.detected === "string", "pm.detected should be a string");
    assert.ok(typeof report.pm.reason === "string", "pm.reason should be a string");
  } finally {
    await rmrf(dir);
  }
});

// ── environment parity across PMs ──────────────────────────────────────

test("comparative: env field is identical across PM runs", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dirNpm = await makeTempDir("comp-bench-env-npm-");
  const dirYarn = await makeTempDir("comp-bench-env-yarn-");
  try {
    const { fakeBin: fakeBinNpm } = await createTestProject(dirNpm);
    const { fakeBin: fakeBinYarn } = await createTestProject(dirYarn, { pm: "yarn" });

    const [npmReport, yarnReport] = await Promise.all([
      runBenchmark(
        dirNpm,
        ["--project-root", ".", "--pm", "npm", "--engine", "pm",
         "--cold-rounds", "0", "--warm-rounds", "1", "--json"],
        { PATH: `${fakeBinNpm}:${process.env.PATH ?? ""}` }
      ),
      runBenchmark(
        dirYarn,
        ["--project-root", ".", "--pm", "yarn", "--engine", "pm",
         "--cold-rounds", "0", "--warm-rounds", "1", "--json"],
        { PATH: `${fakeBinYarn}:${process.env.PATH ?? ""}` }
      )
    ]);

    // Environment should be the same machine regardless of PM
    assert.equal(npmReport.env.platform, yarnReport.env.platform, "platform should match");
    assert.equal(npmReport.env.arch, yarnReport.env.arch, "arch should match");
    assert.equal(npmReport.env.nodeVersion, yarnReport.env.nodeVersion, "nodeVersion should match");
    assert.equal(npmReport.env.cpus, yarnReport.env.cpus, "cpus should match");
    assert.equal(npmReport.env.totalMemoryBytes, yarnReport.env.totalMemoryBytes, "memory should match");
  } finally {
    await Promise.all([rmrf(dirNpm), rmrf(dirYarn)]);
  }
});

// ── multi-round statistical correctness ────────────────────────────────

test("comparative: multi-round warm stats are numerically valid", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-multiround-");
  try {
    const { fakeBin } = await createTestProject(dir);

    const report = await runBenchmark(
      dir,
      ["--project-root", ".", "--pm", "npm", "--engine", "pm",
       "--cold-rounds", "0", "--warm-rounds", "3", "--json"],
      { PATH: `${fakeBin}:${process.env.PATH ?? ""}` }
    );

    const rawStats = report.variants.raw.stats.warm;
    const betterStats = report.variants.betterMinimal.stats.warm;

    // With 3 rounds, stats should be fully populated
    assert.equal(rawStats.count, 3, "raw warm count should be 3");
    assert.equal(betterStats.count, 3, "better warm count should be 3");

    // min <= median <= max
    assert.ok(rawStats.min <= rawStats.median, "raw min <= median");
    assert.ok(rawStats.median <= rawStats.max, "raw median <= max");
    assert.ok(betterStats.min <= betterStats.median, "better min <= median");
    assert.ok(betterStats.median <= betterStats.max, "better median <= max");

    // mean should be between min and max
    assert.ok(rawStats.mean >= rawStats.min, "raw mean >= min");
    assert.ok(rawStats.mean <= rawStats.max, "raw mean <= max");

    // stddev should be non-negative
    if (rawStats.stddev !== null) {
      assert.ok(rawStats.stddev >= 0, "raw stddev should be non-negative");
    }
    if (betterStats.stddev !== null) {
      assert.ok(betterStats.stddev >= 0, "better stddev should be non-negative");
    }

    // p95 should be between median and max (or equal)
    if (rawStats.p95 !== null) {
      assert.ok(rawStats.p95 >= rawStats.median, "raw p95 >= median");
      assert.ok(rawStats.p95 <= rawStats.max, "raw p95 <= max");
    }
  } finally {
    await rmrf(dir);
  }
});

// ── engine=better requires --pm npm ────────────────────────────────────

test("comparative: engine=better rejects non-npm PM", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dir = await makeTempDir("comp-bench-better-reject-");
  try {
    await createTestProject(dir, { pm: "pnpm" });

    await assert.rejects(
      async () => {
        await runBenchmark(dir, [
          "--project-root", ".", "--pm", "pnpm", "--engine", "better",
          "--cold-rounds", "1", "--warm-rounds", "0", "--json"
        ]);
      },
      { message: /engine=better.*requires.*npm/i },
      "should reject engine=better with non-npm PM"
    );
  } finally {
    await rmrf(dir);
  }
});

// ── lockfile parity hashes ─────────────────────────────────────────────

test("comparative: parity hashes differ per lockfile type", async (t) => {
  if (process.platform === "win32") { t.skip("POSIX-only"); return; }

  const dirNpm = await makeTempDir("comp-bench-parity-npm-");
  const dirPnpm = await makeTempDir("comp-bench-parity-pnpm-");
  try {
    const { fakeBin: fakeBinNpm } = await createTestProject(dirNpm);
    const { fakeBin: fakeBinPnpm } = await createTestProject(dirPnpm, { pm: "pnpm" });

    const [npmReport, pnpmReport] = await Promise.all([
      runBenchmark(
        dirNpm,
        ["--project-root", ".", "--pm", "npm", "--engine", "pm",
         "--cold-rounds", "0", "--warm-rounds", "1", "--json"],
        { PATH: `${fakeBinNpm}:${process.env.PATH ?? ""}` }
      ),
      runBenchmark(
        dirPnpm,
        ["--project-root", ".", "--pm", "pnpm", "--engine", "pm",
         "--cold-rounds", "0", "--warm-rounds", "1", "--json"],
        { PATH: `${fakeBinPnpm}:${process.env.PATH ?? ""}` }
      )
    ]);

    // npm project should have package-lock.json hash
    assert.ok(npmReport.parity.lockfiles["package-lock.json"], "npm should hash package-lock.json");

    // pnpm project should have both (since we also create package-lock.json for detect)
    assert.ok(pnpmReport.parity.lockfiles["package-lock.json"], "pnpm project also has package-lock.json");
    assert.ok(pnpmReport.parity.lockfiles["pnpm-lock.yaml"], "pnpm project should hash pnpm-lock.yaml");
  } finally {
    await Promise.all([rmrf(dirNpm), rmrf(dirPnpm)]);
  }
});
